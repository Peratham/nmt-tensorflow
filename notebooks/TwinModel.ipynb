{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from translate.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def twin_model():\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default(), tf.device('/cpu:0'):\n",
    "        with vs.variable_scope('graph_one') as gscope_1:\n",
    "            model_one = Model(source_vocab_size=10, \n",
    "                              target_vocab_size=10,\n",
    "                              buckets=[(3, 3), (6, 6)], \n",
    "                              size=32,\n",
    "                              num_layers=2,\n",
    "                              learning_rate=None,\n",
    "                              max_gradient_norm=5.0, \n",
    "                              batch_size=32,\n",
    "                              use_lstm=True, \n",
    "                              use_local=True,\n",
    "                              optim='adam',\n",
    "                              scope=gscope_1.name,\n",
    "                              num_samples=None)\n",
    "        with vs.variable_scope('graph_two') as gscope_2:\n",
    "            model_two = Model(source_vocab_size=10, \n",
    "                              target_vocab_size=10,\n",
    "                              buckets=[(3, 3), (6, 6)], \n",
    "                              size=32,\n",
    "                              num_layers=2,\n",
    "                              learning_rate=None,\n",
    "                              max_gradient_norm=5.0, \n",
    "                              batch_size=32,\n",
    "                              use_lstm=True, \n",
    "                              use_local=True,\n",
    "                              optim='adam',\n",
    "                              scope=gscope_2.name,\n",
    "                              num_samples=None)\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        g1_tvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=gscope_1.name)\n",
    "        g2_tvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=gscope_2.name)\n",
    "        all_vars = tf.trainable_variables()\n",
    "        \n",
    "    return map(lambda x: x.name, g1_tvars), map(lambda x: x.name, g2_tvars), map(lambda x: x.name, all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1, g2, g = twin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'graph_one/proj_w:0',\n",
       " u'graph_one/proj_b:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/embedding_en:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell0/LSTMCell/W_0:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell0/LSTMCell/B:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell1/LSTMCell/W_0:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell1/LSTMCell/B:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/embedding_de:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/W_a:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/W_c:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/W_p:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/v_p:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/MultiRNNCell/Cell0/LSTMCell/W_0:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/MultiRNNCell/Cell0/LSTMCell/B:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/MultiRNNCell/Cell1/LSTMCell/W_0:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/MultiRNNCell/Cell1/LSTMCell/B:0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'graph_two/proj_w:0',\n",
       " u'graph_two/proj_b:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/embedding_en:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell0/LSTMCell/W_0:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell0/LSTMCell/B:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell1/LSTMCell/W_0:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell1/LSTMCell/B:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/embedding_de:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/W_a:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/W_c:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/W_p:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/v_p:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/MultiRNNCell/Cell0/LSTMCell/W_0:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/MultiRNNCell/Cell0/LSTMCell/B:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/MultiRNNCell/Cell1/LSTMCell/W_0:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/MultiRNNCell/Cell1/LSTMCell/B:0']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'graph_one/proj_w:0',\n",
       " u'graph_one/proj_b:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/embedding_en:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell0/LSTMCell/W_0:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell0/LSTMCell/B:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell1/LSTMCell/W_0:0',\n",
       " u'graph_one/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell1/LSTMCell/B:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/embedding_de:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/W_a:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/W_c:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/W_p:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/v_p:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/MultiRNNCell/Cell0/LSTMCell/W_0:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/MultiRNNCell/Cell0/LSTMCell/B:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/MultiRNNCell/Cell1/LSTMCell/W_0:0',\n",
       " u'graph_one/embedding_attention_s2s/decoder/MultiRNNCell/Cell1/LSTMCell/B:0',\n",
       " u'graph_two/proj_w:0',\n",
       " u'graph_two/proj_b:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/embedding_en:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell0/LSTMCell/W_0:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell0/LSTMCell/B:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell1/LSTMCell/W_0:0',\n",
       " u'graph_two/embedding_attention_s2s/encoder/RNN/MultiRNNCell/Cell1/LSTMCell/B:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/embedding_de:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/W_a:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/W_c:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/W_p:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/v_p:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/MultiRNNCell/Cell0/LSTMCell/W_0:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/MultiRNNCell/Cell0/LSTMCell/B:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/MultiRNNCell/Cell1/LSTMCell/W_0:0',\n",
       " u'graph_two/embedding_attention_s2s/decoder/MultiRNNCell/Cell1/LSTMCell/B:0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.core.framework.device_attributes_pb2 import DeviceAttributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x: x.name ,(filter(lambda x: x.device_type == 'GPU', device_lib.list_local_devices())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.core.framework.device_attributes_pb2.DeviceAttributes"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()[0].__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<property at 0x130e116d8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeviceAttributes.device_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x: x.name, filter(lambda d: d.device_type == 'GPU', \n",
    "                                        device_lib.list_local_devices()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x: x.name, filter(lambda d: d.device_type == 'GPU', \n",
    "                                    device_lib.list_local_devices()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_GPU = ['/gpu:%d' %(i) for i in xrange(len(filter(lambda d: d.device_type == 'GPU', \n",
    "                                                  device_lib.list_local_devices())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
